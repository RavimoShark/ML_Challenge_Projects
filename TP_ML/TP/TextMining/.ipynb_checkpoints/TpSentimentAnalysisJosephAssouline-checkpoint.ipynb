{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "[nltk_data] Downloading package stopwords to /home/joseph/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/joseph/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/joseph/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "# TP Cours ML Telecom ParisTech MDI343\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os.path as op\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from glob import glob\n",
    "from math import exp, expm1, log\n",
    "import re\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "import logging\n",
    "from nltk import SnowballStemmer\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from sklearn.svm import SVC\n",
    "from nltk import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import linear_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset\n",
      "2000 documents\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "print(\"Loading dataset\")\n",
    "\n",
    "filenames_neg = sorted(glob(op.join('83data/data/imdb1/neg', '*.txt')))\n",
    "filenames_pos = sorted(glob(op.join('83data/data/imdb1/pos', '*.txt')))\n",
    "\n",
    "texts_neg = [open(f).read() for f in filenames_neg]\n",
    "texts_pos = [open(f).read() for f in filenames_pos]\n",
    "texts = texts_neg + texts_pos\n",
    "y = np.ones(len(texts), dtype=np.int)\n",
    "y[:len(texts_neg)] = 0.\n",
    "\n",
    "print(\"%d documents\" % len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "StopList = open(\n",
    "    '/home/joseph/Dropbox/DeepLearning/Cours/MDI343/TP/TextMining/83data/data/english.stop').read().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def RemoveStopWord(d):\n",
    "\n",
    "    for x in StopList:\n",
    "        if x in d.keys():\n",
    "            del d[x]\n",
    "    return d\n",
    "\n",
    "\n",
    "def count_words(texts, R, regexp):\n",
    "    i = 0\n",
    "    line = -1\n",
    "    s = 0\n",
    "    \"\"\"Vectorize text : return count of each word in the text snippets\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    texts : list of str\n",
    "        The texts\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    vocabulary : dict\n",
    "        A dictionary that points to an index in counts for each word.\n",
    "    counts : ndarray, shape (n_samples, n_features)\n",
    "        The counts of each word in each text.\n",
    "        n_samples == number of documents.\n",
    "        n_features == number of words in vocabulary.\n",
    "    \"\"\"\n",
    "    wordcountlist = []\n",
    "    d = dict()\n",
    "    words = set()\n",
    "    for text in texts:\n",
    "        if R:\n",
    "            d = RemoveStopWord(Counter(re.findall(regexp, text)))\n",
    "        else:\n",
    "            d = Counter(re.findall(regexp, text))\n",
    "\n",
    "        words.update(d.keys())\n",
    "        wordcountlist.append(d)\n",
    "\n",
    "    counts = np.zeros((len(texts), len(words)))\n",
    "    vocabulary = {word: i for i, word in enumerate(sorted(words))}\n",
    "\n",
    "    for wc in wordcountlist:\n",
    "        line += 1\n",
    "        for word in wc.keys():\n",
    "            counts[line, vocabulary[word]] = wc[word]\n",
    "\n",
    "    return vocabulary, counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39696 (2000, 39696)\n"
     ]
    }
   ],
   "source": [
    "v, c = count_words(texts, False, r\"[\\w]+\")\n",
    "print(len(v), c.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question numéro 2:\n",
    "   Les classes positives et négatives ont été assignées à l'aide du rating donné au film.\n",
    "   Ainsi lorsque rating >= int(TotalRating/2+1) c'est considéré comme positif."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NB(BaseEstimator, ClassifierMixin):\n",
    "\n",
    "    def __init__(self, RemoveStopWord=False, prior=None, vocabulary=None,\n",
    "                 cond_prob=None, Npos=None, Nneg=None, scoring=None, regexp=r\"[\\w]+\"):\n",
    "        self.RemoveStopWord = RemoveStopWord\n",
    "        self.vocabulary = vocabulary\n",
    "        self.prior = prior\n",
    "        self.cond_prob = cond_prob\n",
    "        self.scoring = scoring\n",
    "        self.regexp = regexp\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.vocabulary, self.counts = count_words(\n",
    "            X, self.RemoveStopWord, self.regexp)\n",
    "        N = len(y)\n",
    "        cardvocab = len(self.vocabulary.keys())\n",
    "        Npos = np.where(y == 1)  # Classe positive\n",
    "        Nneg = np.where(y == 0)  # Classe negative\n",
    "        self.prior = np.array([len(Nneg) / N, len(Npos) / N])\n",
    "        self.cond_prob = np.zeros((2, cardvocab))\n",
    "        self.cond_prob[1, :] = np.log((np.sum(\n",
    "            self.counts[Npos], axis=0) + 1) / (np.sum(self.counts[Npos]) + cardvocab))\n",
    "        self.cond_prob[0, :] = np.log((np.sum(\n",
    "            self.counts[Nneg], axis=0) + 1) / (np.sum(self.counts[Nneg]) + cardvocab))\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predictMat(self, X):\n",
    "        i = 0\n",
    "        score = np.zeros(len(X))\n",
    "        wordcountlist = []\n",
    "        for x in X:\n",
    "            d = Counter(re.findall(self.regexp, x))\n",
    "            if self.RemoveStopWord:\n",
    "                d = RemoveStopWord(d)\n",
    "            wordcountlist.append(d)\n",
    "\n",
    "        counts = np.zeros((len(X), len(self.vocabulary)))\n",
    "        for line, wc in enumerate(wordcountlist):\n",
    "            for word in wc.keys():\n",
    "                # on laisse tomber les mots sur lesquels on s'est pas entrainé\n",
    "                if word in self.vocabulary:\n",
    "                    counts[line, self.vocabulary[word]] = wc[word]\n",
    "        bigprior = np.tile(self.prior, (len(X), 1))\n",
    "        score = np.argmax(np.dot(counts, self.cond_prob.T) +\n",
    "                          np.log(bigprior), axis=1)\n",
    "\n",
    "        return score\n",
    "\n",
    "    def predict(self, X):\n",
    "        # comptage comme a la Q1 mais avec vocabulaire de taille imposé\n",
    "        wordcountlist = []\n",
    "        for x in X:\n",
    "            d = Counter(re.findall(self.regexp, x))\n",
    "            if self.RemoveStopWord:\n",
    "                d = RemoveStopWord(d)\n",
    "            wordcountlist.append(d)\n",
    "\n",
    "        counts = np.zeros((len(X), len(self.vocabulary)))\n",
    "\n",
    "        for line, wc in enumerate(wordcountlist):\n",
    "            for word in wc.keys():\n",
    "                # on laisse tomber les mots sur lesquels on s'est pas entrainé\n",
    "                if word in self.vocabulary:\n",
    "                    counts[line, self.vocabulary[word]] = wc[word]\n",
    "        # maintenant tu as les comptes aux bons endroits\n",
    "        print(counts.shape)\n",
    "        nb_classes = self.cond_prob.shape[0]\n",
    "        # sc stock la proba d'apppartenance a la classe pour chaque sample de X\n",
    "        # a predire\n",
    "        sc = np.zeros((len(X), nb_classes))\n",
    "\n",
    "        for num_class, prior_class in enumerate(self.prior):\n",
    "            # broadcasting du log du prior de la classe sur tous les samples\n",
    "            sc[:, num_class] = np.log(\n",
    "                prior_class) + np.sum(counts * self.cond_prob[num_class, :], axis=1)\n",
    "\n",
    "            # puis ajout de la somme des nb d'occurences du terme * log de sa\n",
    "            # proba pour la classe\n",
    "\n",
    "        # on predit que la classe majoritaire a la fin\n",
    "        y_pred = np.argmax(sc, axis=1)\n",
    "        return y_pred\n",
    "\n",
    "    def score(self, X, y):\n",
    "        if self.scoring == 'Mat':\n",
    "            return np.mean(self.predictMat(X) == y)\n",
    "        else:\n",
    "            return np.mean(self.predict(X) == y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 29750)\n",
      "0.81\n"
     ]
    }
   ],
   "source": [
    "X = texts\n",
    "nb = NB()\n",
    "nb.fit(X[::2], y[::2])\n",
    "print(nb.score(X[1::2], y[1::2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question Numéro 4\n",
    "Cross Validation 5 folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul Matriciel\n",
    "nbMat = NB(scoring='Mat', RemoveStopWord=False)\n",
    "scores_Mat = cross_val_score(nbMat, X, y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.81 (+/- 0.03)\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" %\n",
    "      (scores_Mat.mean(), scores_Mat.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question numéro 5 \n",
    "Avec Stop Words et changement de la regexp -> reduction aux mots et ponctuations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regexp for capturing word and punctuation without digits\n",
    "regexp = r\"[a-zA-Z]+[;.,!?:]?|[a-zA-Z]+\"\n",
    "nbOptim = NB(RemoveStopWord=True, scoring='Mat')\n",
    "scores_Optim = cross_val_score(nbOptim, X, y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.795 ,  0.81  ,  0.8   ,  0.825 ,  0.7725])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_Optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.80 (+/- 0.03)\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" %\n",
    "      (scores_Optim.mean(), scores_Optim.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.80 (+/- 0.03)\n"
     ]
    }
   ],
   "source": [
    "# test with the regexp\n",
    "regexp = r\"[a-zA-Z]+[;.,!?:]?|[a-zA-Z]+\"\n",
    "nbOptimrg = NB(RemoveStopWord=True, scoring='Mat')\n",
    "scores_Optimrg = cross_val_score(nbOptim, X, y, cv=5)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" %\n",
    "      (scores_Optimrg.mean(), scores_Optimrg.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En conclusion les stop words et certains characteres \n",
    "que l'on pourrait croire seulement du bruit apportent une information pour la classification!!!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 eme partie\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question numéro 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelineStd = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('clf', MultinomialNB()),\n",
    "])\n",
    "\n",
    "pipelineOpt = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SGDClassifier(max_iter=1000, tol=1e-3)),\n",
    "])\n",
    "\n",
    "pipelineRf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', RandomForestClassifier()),\n",
    "])\n",
    "\n",
    "pipelineLR = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', linear_model.LogisticRegression(C=1e5)),\n",
    "])\n",
    "\n",
    "\n",
    "parametersOptRf = {\n",
    "    #'vect__max_df': (0.5, 0.75, 1.0),\n",
    "    #'vect__max_features': (None, 5000, 10000, 50000),\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)),  # unigrams or bigrams\n",
    "    'tfidf__use_idf': (True, False),\n",
    "    'tfidf__norm': ('l1', 'l2'),\n",
    "    #'clf__max_iter': (10, 50, 80),\n",
    "}\n",
    "\n",
    "parametersOptLR = {\n",
    "    #'vect__max_df': (0.5, 0.75, 1.0),\n",
    "    #'vect__max_features': (None, 5000, 10000, 50000),\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)),  # unigrams or bigrams\n",
    "    'tfidf__use_idf': (True, False),\n",
    "    'tfidf__norm': ('l1', 'l2'),\n",
    "    'clf__multi_class': ['ovr'],\n",
    "    'clf__solver': ['newton-cg', 'lbfgs', 'sag', 'saga'],\n",
    "}\n",
    "\n",
    "\n",
    "parametersStd = {\n",
    "    #    'vect__max_df': (0.5, 0.75, 1.0),\n",
    "    #'vect__max_features': (None, 5000, 10000, 50000),\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)),  # unigrams or bigrams\n",
    "    'vect__analyzer': ('word', 'char'),\n",
    "    #'tfidf__use_idf': (True, False),\n",
    "    #'tfidf__norm': ('l1', 'l2'),\n",
    "    #'clf__alpha': (0.00001, 0.000001),\n",
    "    #'clf__penalty': ('l2', 'elasticnet'),\n",
    "    #'clf__n_iter': (10, 50, 80),\n",
    "}\n",
    "\n",
    "parametersOpt = {\n",
    "    #'vect__max_df': (0.5, 0.75, 1.0),\n",
    "    #'vect__max_features': (None, 5000, 10000, 50000),\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)),  # unigrams or bigrams\n",
    "    'tfidf__use_idf': (True, False),\n",
    "    'tfidf__norm': ('l1', 'l2'),\n",
    "    'clf__alpha': (0.00001, 0.000001),\n",
    "    'clf__penalty': ('l2', 'elasticnet'),\n",
    "    #'clf__max_iter': (10, 50, 80),\n",
    "}\n",
    "\n",
    "parametersOpt1 = {\n",
    "    #'vect__max_df': (0.5, 0.75, 1.0),\n",
    "    #'vect__max_features': (None, 5000, 10000, 50000),\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)),  # unigrams or bigrams\n",
    "    'tfidf__use_idf': (True, False),\n",
    "    'tfidf__norm': ('l1', 'l2'),\n",
    "    #'clf__alpha': (0.00001, 0.000001),\n",
    "    #'clf__penalty': ('l2', 'elasticnet'),\n",
    "    #'clf__max_iter': (10, 50, 80),\n",
    "}\n",
    "\n",
    "\n",
    "def LaunchGSearch(grid_search, X, Y, parameters):\n",
    "    t0 = time()\n",
    "    grid_search.fit(X, Y)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "    print()\n",
    "    print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:   29.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 34.247s\n",
      "\n",
      "Best score: 0.831\n",
      "Best parameters set:\n",
      "\tvect__analyzer: 'word'\n",
      "\tvect__ngram_range: (1, 2)\n"
     ]
    }
   ],
   "source": [
    "grid_search = GridSearchCV(pipelineStd, parametersStd, n_jobs=-1, verbose=1, cv=5)\n",
    "LaunchGSearch(grid_search, X, y, parametersStd)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut conclure que la configuration optimal est la separation \n",
    "par mots et la comparaison en sous chaine de 1à 2 characteres.\n",
    "Le résultat est ainsi amélioré."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question numéro 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   44.4s\n",
      "[Parallel(n_jobs=-1)]: Done 160 out of 160 | elapsed:  3.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 222.169s\n",
      "\n",
      "Best score: 0.858\n",
      "Best parameters set:\n",
      "\tclf__alpha: 1e-06\n",
      "\tclf__penalty: 'elasticnet'\n",
      "\ttfidf__norm: 'l2'\n",
      "\ttfidf__use_idf: True\n",
      "\tvect__ngram_range: (1, 2)\n"
     ]
    }
   ],
   "source": [
    "#utilisation pipeline optimale avec TfIdf\n",
    "grid_searchopt = GridSearchCV(pipelineOpt, parametersOpt, n_jobs=-1, verbose=1, cv=5)\n",
    "LaunchGSearch(grid_searchopt, X, y, parametersOpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On voit que le Tfidf avec un sgd classifier fais grimper notre score -> 0.858"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question numéro 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'run'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer2 = SnowballStemmer(\"english\")\n",
    "stemmer2.stem(\"running\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = CountVectorizer().build_analyzer()\n",
    "def stemmed_words(doc):\n",
    "    return (stemmer2.stem(w) for w in analyzer(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelineOptPrep = Pipeline([\n",
    "    ('vect', CountVectorizer(analyzer=stemmed_words)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SGDClassifier(max_iter=1000, tol=1e-3)),\n",
    "])\n",
    "\n",
    "parametersOpt1 = {\n",
    "    #'vect__max_df': (0.5, 0.75, 1.0),\n",
    "    #'vect__max_features': (None, 5000, 10000, 50000),\n",
    "    'vect__ngram_range': [(1, 2)],  # unigrams or bigrams\n",
    "    #'tfidf__use_idf': (True),\n",
    "    'tfidf__norm': ['l2'],\n",
    "    'clf__alpha': [0.000001],\n",
    "    'clf__penalty': ['elasticnet'],\n",
    "    #'clf__max_iter': (10, 50, 80),\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   45.5s remaining:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   47.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 61.559s\n",
      "\n",
      "Best score: 0.839\n",
      "Best parameters set:\n",
      "\tclf__alpha: 1e-06\n",
      "\tclf__penalty: 'elasticnet'\n",
      "\ttfidf__norm: 'l2'\n",
      "\ttfidf__use_idf: True\n",
      "\tvect__ngram_range: (1, 2)\n"
     ]
    }
   ],
   "source": [
    "grid_searchopt = GridSearchCV(pipelineOptPrep, parametersOpt1, n_jobs=-1, verbose=1, cv=5)\n",
    "LaunchGSearch(grid_searchopt, X, y, parametersOpt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('plot', 'NN'),\n",
       " (':', ':'),\n",
       " ('two', 'CD'),\n",
       " ('teen', 'NN'),\n",
       " ('couples', 'NNS'),\n",
       " ('go', 'VBP'),\n",
       " ('to', 'TO'),\n",
       " ('a', 'DT'),\n",
       " ('church', 'NN'),\n",
       " ('party', 'NN'),\n",
       " (',', ','),\n",
       " ('drink', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('then', 'RB'),\n",
       " ('drive', 'NN'),\n",
       " ('.', '.'),\n",
       " ('they', 'PRP'),\n",
       " ('get', 'VBP'),\n",
       " ('into', 'IN'),\n",
       " ('an', 'DT'),\n",
       " ('accident', 'NN'),\n",
       " ('.', '.'),\n",
       " ('one', 'CD'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('guys', 'NN'),\n",
       " ('dies', 'VBZ'),\n",
       " (',', ','),\n",
       " ('but', 'CC'),\n",
       " ('his', 'PRP$'),\n",
       " ('girlfriend', 'NN'),\n",
       " ('continues', 'VBZ'),\n",
       " ('to', 'TO'),\n",
       " ('see', 'VB'),\n",
       " ('him', 'PRP'),\n",
       " ('in', 'IN'),\n",
       " ('her', 'PRP$'),\n",
       " ('life', 'NN'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('has', 'VBZ'),\n",
       " ('nightmares', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('what', 'WP'),\n",
       " (\"'s\", 'VBZ'),\n",
       " ('the', 'DT'),\n",
       " ('deal', 'NN'),\n",
       " ('?', '.'),\n",
       " ('watch', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('movie', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('``', '``'),\n",
       " ('sorta', 'JJ'),\n",
       " ('``', '``'),\n",
       " ('find', 'VB'),\n",
       " ('out', 'RP'),\n",
       " ('.', '.'),\n",
       " ('.', '.'),\n",
       " ('.', '.'),\n",
       " ('critique', 'NN'),\n",
       " (':', ':'),\n",
       " ('a', 'DT'),\n",
       " ('mind-fuck', 'JJ'),\n",
       " ('movie', 'NN'),\n",
       " ('for', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('teen', 'JJ'),\n",
       " ('generation', 'NN'),\n",
       " ('that', 'WDT'),\n",
       " ('touches', 'VBZ'),\n",
       " ('on', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('very', 'RB'),\n",
       " ('cool', 'JJ'),\n",
       " ('idea', 'NN'),\n",
       " (',', ','),\n",
       " ('but', 'CC'),\n",
       " ('presents', 'VBZ'),\n",
       " ('it', 'PRP'),\n",
       " ('in', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('very', 'RB'),\n",
       " ('bad', 'JJ'),\n",
       " ('package', 'NN'),\n",
       " ('.', '.'),\n",
       " ('which', 'WDT'),\n",
       " ('is', 'VBZ'),\n",
       " ('what', 'WP'),\n",
       " ('makes', 'VBZ'),\n",
       " ('this', 'DT'),\n",
       " ('review', 'NN'),\n",
       " ('an', 'DT'),\n",
       " ('even', 'RB'),\n",
       " ('harder', 'RBR'),\n",
       " ('one', 'CD'),\n",
       " ('to', 'TO'),\n",
       " ('write', 'VB'),\n",
       " (',', ','),\n",
       " ('since', 'IN'),\n",
       " ('i', 'NN'),\n",
       " ('generally', 'RB'),\n",
       " ('applaud', 'VBP'),\n",
       " ('films', 'NNS'),\n",
       " ('which', 'WDT'),\n",
       " ('attempt', 'VBP'),\n",
       " ('to', 'TO'),\n",
       " ('break', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('mold', 'NN'),\n",
       " (',', ','),\n",
       " ('mess', 'NN'),\n",
       " ('with', 'IN'),\n",
       " ('your', 'PRP$'),\n",
       " ('head', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('such', 'JJ'),\n",
       " ('(', '('),\n",
       " ('lost', 'VBN'),\n",
       " ('highway', 'NN'),\n",
       " ('&', 'CC'),\n",
       " ('memento', 'NN'),\n",
       " (')', ')'),\n",
       " (',', ','),\n",
       " ('but', 'CC'),\n",
       " ('there', 'EX'),\n",
       " ('are', 'VBP'),\n",
       " ('good', 'JJ'),\n",
       " ('and', 'CC'),\n",
       " ('bad', 'JJ'),\n",
       " ('ways', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('making', 'VBG'),\n",
       " ('all', 'DT'),\n",
       " ('types', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('films', 'NNS'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('these', 'DT'),\n",
       " ('folks', 'NNS'),\n",
       " ('just', 'RB'),\n",
       " ('did', 'VBD'),\n",
       " (\"n't\", 'RB'),\n",
       " ('snag', 'VB'),\n",
       " ('this', 'DT'),\n",
       " ('one', 'CD'),\n",
       " ('correctly', 'RB'),\n",
       " ('.', '.'),\n",
       " ('they', 'PRP'),\n",
       " ('seem', 'VBP'),\n",
       " ('to', 'TO'),\n",
       " ('have', 'VB'),\n",
       " ('taken', 'VBN'),\n",
       " ('this', 'DT'),\n",
       " ('pretty', 'RB'),\n",
       " ('neat', 'JJ'),\n",
       " ('concept', 'NN'),\n",
       " (',', ','),\n",
       " ('but', 'CC'),\n",
       " ('executed', 'VBD'),\n",
       " ('it', 'PRP'),\n",
       " ('terribly', 'RB'),\n",
       " ('.', '.'),\n",
       " ('so', 'IN'),\n",
       " ('what', 'WP'),\n",
       " ('are', 'VBP'),\n",
       " ('the', 'DT'),\n",
       " ('problems', 'NNS'),\n",
       " ('with', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('movie', 'NN'),\n",
       " ('?', '.'),\n",
       " ('well', 'RB'),\n",
       " (',', ','),\n",
       " ('its', 'PRP$'),\n",
       " ('main', 'JJ'),\n",
       " ('problem', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('that', 'IN'),\n",
       " ('it', 'PRP'),\n",
       " (\"'s\", 'VBZ'),\n",
       " ('simply', 'RB'),\n",
       " ('too', 'RB'),\n",
       " ('jumbled', 'VBN'),\n",
       " ('.', '.'),\n",
       " ('it', 'PRP'),\n",
       " ('starts', 'VBZ'),\n",
       " ('off', 'IN'),\n",
       " ('``', '``'),\n",
       " ('normal', 'JJ'),\n",
       " ('``', '``'),\n",
       " ('but', 'CC'),\n",
       " ('then', 'RB'),\n",
       " ('downshifts', 'VBZ'),\n",
       " ('into', 'IN'),\n",
       " ('this', 'DT'),\n",
       " ('``', '``'),\n",
       " ('fantasy', 'JJ'),\n",
       " ('``', '``'),\n",
       " ('world', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('which', 'WDT'),\n",
       " ('you', 'PRP'),\n",
       " (',', ','),\n",
       " ('as', 'IN'),\n",
       " ('an', 'DT'),\n",
       " ('audience', 'NN'),\n",
       " ('member', 'NN'),\n",
       " (',', ','),\n",
       " ('have', 'VBP'),\n",
       " ('no', 'DT'),\n",
       " ('idea', 'NN'),\n",
       " ('what', 'WP'),\n",
       " (\"'s\", 'VBZ'),\n",
       " ('going', 'VBG'),\n",
       " ('on', 'IN'),\n",
       " ('.', '.'),\n",
       " ('there', 'EX'),\n",
       " ('are', 'VBP'),\n",
       " ('dreams', 'NNS'),\n",
       " (',', ','),\n",
       " ('there', 'EX'),\n",
       " ('are', 'VBP'),\n",
       " ('characters', 'NNS'),\n",
       " ('coming', 'VBG'),\n",
       " ('back', 'RB'),\n",
       " ('from', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('dead', 'JJ'),\n",
       " (',', ','),\n",
       " ('there', 'EX'),\n",
       " ('are', 'VBP'),\n",
       " ('others', 'NNS'),\n",
       " ('who', 'WP'),\n",
       " ('look', 'VBP'),\n",
       " ('like', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('dead', 'JJ'),\n",
       " (',', ','),\n",
       " ('there', 'EX'),\n",
       " ('are', 'VBP'),\n",
       " ('strange', 'JJ'),\n",
       " ('apparitions', 'NNS'),\n",
       " (',', ','),\n",
       " ('there', 'EX'),\n",
       " ('are', 'VBP'),\n",
       " ('disappearances', 'NNS'),\n",
       " (',', ','),\n",
       " ('there', 'EX'),\n",
       " ('are', 'VBP'),\n",
       " ('a', 'DT'),\n",
       " ('looooot', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('chase', 'NN'),\n",
       " ('scenes', 'NNS'),\n",
       " (',', ','),\n",
       " ('there', 'EX'),\n",
       " ('are', 'VBP'),\n",
       " ('tons', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('weird', 'JJ'),\n",
       " ('things', 'NNS'),\n",
       " ('that', 'WDT'),\n",
       " ('happen', 'VBP'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('most', 'JJS'),\n",
       " ('of', 'IN'),\n",
       " ('it', 'PRP'),\n",
       " ('is', 'VBZ'),\n",
       " ('simply', 'RB'),\n",
       " ('not', 'RB'),\n",
       " ('explained', 'VBN'),\n",
       " ('.', '.'),\n",
       " ('now', 'RB'),\n",
       " ('i', 'VBZ'),\n",
       " ('personally', 'RB'),\n",
       " ('do', 'VBP'),\n",
       " (\"n't\", 'RB'),\n",
       " ('mind', 'VB'),\n",
       " ('trying', 'VBG'),\n",
       " ('to', 'TO'),\n",
       " ('unravel', 'VB'),\n",
       " ('a', 'DT'),\n",
       " ('film', 'NN'),\n",
       " ('every', 'DT'),\n",
       " ('now', 'RB'),\n",
       " ('and', 'CC'),\n",
       " ('then', 'RB'),\n",
       " (',', ','),\n",
       " ('but', 'CC'),\n",
       " ('when', 'WRB'),\n",
       " ('all', 'DT'),\n",
       " ('it', 'PRP'),\n",
       " ('does', 'VBZ'),\n",
       " ('is', 'VBZ'),\n",
       " ('give', 'VB'),\n",
       " ('me', 'PRP'),\n",
       " ('the', 'DT'),\n",
       " ('same', 'JJ'),\n",
       " ('clue', 'NN'),\n",
       " ('over', 'IN'),\n",
       " ('and', 'CC'),\n",
       " ('over', 'RB'),\n",
       " ('again', 'RB'),\n",
       " (',', ','),\n",
       " ('i', 'JJ'),\n",
       " ('get', 'VBP'),\n",
       " ('kind', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('fed', 'VBN'),\n",
       " ('up', 'RP'),\n",
       " ('after', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('while', 'NN'),\n",
       " (',', ','),\n",
       " ('which', 'WDT'),\n",
       " ('is', 'VBZ'),\n",
       " ('this', 'DT'),\n",
       " ('film', 'NN'),\n",
       " (\"'s\", 'POS'),\n",
       " ('biggest', 'JJS'),\n",
       " ('problem', 'NN'),\n",
       " ('.', '.'),\n",
       " ('it', 'PRP'),\n",
       " (\"'s\", 'VBZ'),\n",
       " ('obviously', 'RB'),\n",
       " ('got', 'VBD'),\n",
       " ('this', 'DT'),\n",
       " ('big', 'JJ'),\n",
       " ('secret', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('hide', 'VB'),\n",
       " (',', ','),\n",
       " ('but', 'CC'),\n",
       " ('it', 'PRP'),\n",
       " ('seems', 'VBZ'),\n",
       " ('to', 'TO'),\n",
       " ('want', 'VB'),\n",
       " ('to', 'TO'),\n",
       " ('hide', 'VB'),\n",
       " ('it', 'PRP'),\n",
       " ('completely', 'RB'),\n",
       " ('until', 'IN'),\n",
       " ('its', 'PRP$'),\n",
       " ('final', 'JJ'),\n",
       " ('five', 'CD'),\n",
       " ('minutes', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('and', 'CC'),\n",
       " ('do', 'VBP'),\n",
       " ('they', 'PRP'),\n",
       " ('make', 'VB'),\n",
       " ('things', 'NNS'),\n",
       " ('entertaining', 'VBG'),\n",
       " (',', ','),\n",
       " ('thrilling', 'VBG'),\n",
       " ('or', 'CC'),\n",
       " ('even', 'RB'),\n",
       " ('engaging', 'VBG'),\n",
       " (',', ','),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('meantime', 'NN'),\n",
       " ('?', '.'),\n",
       " ('not', 'RB'),\n",
       " ('really', 'RB'),\n",
       " ('.', '.'),\n",
       " ('the', 'DT'),\n",
       " ('sad', 'JJ'),\n",
       " ('part', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('that', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('arrow', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('i', 'VB'),\n",
       " ('both', 'DT'),\n",
       " ('dig', 'NN'),\n",
       " ('on', 'IN'),\n",
       " ('flicks', 'NNS'),\n",
       " ('like', 'IN'),\n",
       " ('this', 'DT'),\n",
       " (',', ','),\n",
       " ('so', 'IN'),\n",
       " ('we', 'PRP'),\n",
       " ('actually', 'RB'),\n",
       " ('figured', 'VBD'),\n",
       " ('most', 'JJS'),\n",
       " ('of', 'IN'),\n",
       " ('it', 'PRP'),\n",
       " ('out', 'RP'),\n",
       " ('by', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('half-way', 'JJ'),\n",
       " ('point', 'NN'),\n",
       " (',', ','),\n",
       " ('so', 'IN'),\n",
       " ('all', 'DT'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('strangeness', 'NN'),\n",
       " ('after', 'IN'),\n",
       " ('that', 'DT'),\n",
       " ('did', 'VBD'),\n",
       " ('start', 'VB'),\n",
       " ('to', 'TO'),\n",
       " ('make', 'VB'),\n",
       " ('a', 'DT'),\n",
       " ('little', 'JJ'),\n",
       " ('bit', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('sense', 'NN'),\n",
       " (',', ','),\n",
       " ('but', 'CC'),\n",
       " ('it', 'PRP'),\n",
       " ('still', 'RB'),\n",
       " ('did', 'VBD'),\n",
       " (\"n't\", 'RB'),\n",
       " ('the', 'DT'),\n",
       " ('make', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('film', 'NN'),\n",
       " ('all', 'PDT'),\n",
       " ('that', 'IN'),\n",
       " ('more', 'JJR'),\n",
       " ('entertaining', 'NN'),\n",
       " ('.', '.'),\n",
       " ('i', 'NN'),\n",
       " ('guess', 'VBD'),\n",
       " ('the', 'DT'),\n",
       " ('bottom', 'JJ'),\n",
       " ('line', 'NN'),\n",
       " ('with', 'IN'),\n",
       " ('movies', 'NNS'),\n",
       " ('like', 'IN'),\n",
       " ('this', 'DT'),\n",
       " ('is', 'VBZ'),\n",
       " ('that', 'IN'),\n",
       " ('you', 'PRP'),\n",
       " ('should', 'MD'),\n",
       " ('always', 'RB'),\n",
       " ('make', 'VB'),\n",
       " ('sure', 'JJ'),\n",
       " ('that', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('audience', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('``', '``'),\n",
       " ('into', 'IN'),\n",
       " ('it', 'PRP'),\n",
       " ('``', '``'),\n",
       " ('even', 'RB'),\n",
       " ('before', 'IN'),\n",
       " ('they', 'PRP'),\n",
       " ('are', 'VBP'),\n",
       " ('given', 'VBN'),\n",
       " ('the', 'DT'),\n",
       " ('secret', 'JJ'),\n",
       " ('password', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('enter', 'VB'),\n",
       " ('your', 'PRP$'),\n",
       " ('world', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('understanding', 'VBG'),\n",
       " ('.', '.'),\n",
       " ('i', 'JJ'),\n",
       " ('mean', 'VBP'),\n",
       " (',', ','),\n",
       " ('showing', 'VBG'),\n",
       " ('melissa', 'JJ'),\n",
       " ('sagemiller', 'NN'),\n",
       " ('running', 'VBG'),\n",
       " ('away', 'RB'),\n",
       " ('from', 'IN'),\n",
       " ('visions', 'NNS'),\n",
       " ('for', 'IN'),\n",
       " ('about', 'IN'),\n",
       " ('20', 'CD'),\n",
       " ('minutes', 'NNS'),\n",
       " ('throughout', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('movie', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('just', 'RB'),\n",
       " ('plain', 'JJ'),\n",
       " ('lazy', 'JJ'),\n",
       " ('!', '.'),\n",
       " ('!', '.'),\n",
       " ('okay', 'NN'),\n",
       " (',', ','),\n",
       " ('we', 'PRP'),\n",
       " ('get', 'VBP'),\n",
       " ('it', 'PRP'),\n",
       " ('.', '.'),\n",
       " ('.', '.'),\n",
       " ('.', '.'),\n",
       " ('there', 'EX'),\n",
       " ('are', 'VBP'),\n",
       " ('people', 'NNS'),\n",
       " ('chasing', 'VBG'),\n",
       " ('her', 'PRP$'),\n",
       " ('and', 'CC'),\n",
       " ('we', 'PRP'),\n",
       " ('do', 'VBP'),\n",
       " (\"n't\", 'RB'),\n",
       " ('know', 'VB'),\n",
       " ('who', 'WP'),\n",
       " ('they', 'PRP'),\n",
       " ('are', 'VBP'),\n",
       " ('.', '.'),\n",
       " ('do', 'VBP'),\n",
       " ('we', 'PRP'),\n",
       " ('really', 'RB'),\n",
       " ('need', 'VB'),\n",
       " ('to', 'TO'),\n",
       " ('see', 'VB'),\n",
       " ('it', 'PRP'),\n",
       " ('over', 'IN'),\n",
       " ('and', 'CC'),\n",
       " ('over', 'RB'),\n",
       " ('again', 'RB'),\n",
       " ('?', '.'),\n",
       " ('how', 'WRB'),\n",
       " ('about', 'IN'),\n",
       " ('giving', 'VBG'),\n",
       " ('us', 'PRP'),\n",
       " ('different', 'JJ'),\n",
       " ('scenes', 'NNS'),\n",
       " ('offering', 'VBG'),\n",
       " ('further', 'JJ'),\n",
       " ('insight', 'NN'),\n",
       " ('into', 'IN'),\n",
       " ('all', 'DT'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('strangeness', 'NN'),\n",
       " ('going', 'VBG'),\n",
       " ('down', 'RP'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('movie', 'NN'),\n",
       " ('?', '.'),\n",
       " ('apparently', 'RB'),\n",
       " (',', ','),\n",
       " ('the', 'DT'),\n",
       " ('studio', 'NN'),\n",
       " ('took', 'VBD'),\n",
       " ('this', 'DT'),\n",
       " ('film', 'NN'),\n",
       " ('away', 'RB'),\n",
       " ('from', 'IN'),\n",
       " ('its', 'PRP$'),\n",
       " ('director', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('chopped', 'VBD'),\n",
       " ('it', 'PRP'),\n",
       " ('up', 'RP'),\n",
       " ('themselves', 'PRP'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('it', 'PRP'),\n",
       " ('shows', 'VBZ'),\n",
       " ('.', '.'),\n",
       " ('there', 'EX'),\n",
       " ('might', 'MD'),\n",
       " (\"'ve\", 'VBP'),\n",
       " ('been', 'VBN'),\n",
       " ('a', 'DT'),\n",
       " ('pretty', 'JJ'),\n",
       " ('decent', 'JJ'),\n",
       " ('teen', 'JJ'),\n",
       " ('mind-fuck', 'JJ'),\n",
       " ('movie', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('here', 'RB'),\n",
       " ('somewhere', 'RB'),\n",
       " (',', ','),\n",
       " ('but', 'CC'),\n",
       " ('i', 'VBZ'),\n",
       " ('guess', 'VBP'),\n",
       " ('``', '``'),\n",
       " ('the', 'DT'),\n",
       " ('suits', 'NNS'),\n",
       " ('``', '``'),\n",
       " ('decided', 'VBD'),\n",
       " ('that', 'IN'),\n",
       " ('turning', 'VBG'),\n",
       " ('it', 'PRP'),\n",
       " ('into', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('music', 'NN'),\n",
       " ('video', 'NN'),\n",
       " ('with', 'IN'),\n",
       " ('little', 'JJ'),\n",
       " ('edge', 'NN'),\n",
       " (',', ','),\n",
       " ('would', 'MD'),\n",
       " ('make', 'VB'),\n",
       " ('more', 'JJR'),\n",
       " ('sense', 'NN'),\n",
       " ('.', '.'),\n",
       " ('the', 'DT'),\n",
       " ('actors', 'NNS'),\n",
       " ('are', 'VBP'),\n",
       " ('pretty', 'RB'),\n",
       " ('good', 'JJ'),\n",
       " ('for', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('most', 'JJS'),\n",
       " ('part', 'NN'),\n",
       " (',', ','),\n",
       " ('although', 'IN'),\n",
       " ('wes', 'JJ'),\n",
       " ('bentley', 'NN'),\n",
       " ('just', 'RB'),\n",
       " ('seemed', 'VBD'),\n",
       " ('to', 'TO'),\n",
       " ('be', 'VB'),\n",
       " ('playing', 'VBG'),\n",
       " ('the', 'DT'),\n",
       " ('exact', 'JJ'),\n",
       " ('same', 'JJ'),\n",
       " ('character', 'NN'),\n",
       " ('that', 'IN'),\n",
       " ('he', 'PRP'),\n",
       " ('did', 'VBD'),\n",
       " ('in', 'IN'),\n",
       " ('american', 'JJ'),\n",
       " ('beauty', 'NN'),\n",
       " (',', ','),\n",
       " ('only', 'RB'),\n",
       " ('in', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('new', 'JJ'),\n",
       " ('neighborhood', 'NN'),\n",
       " ('.', '.'),\n",
       " ('but', 'CC'),\n",
       " ('my', 'PRP$'),\n",
       " ('biggest', 'JJS'),\n",
       " ('kudos', 'NN'),\n",
       " ('go', 'VBP'),\n",
       " ('out', 'RP'),\n",
       " ('to', 'TO'),\n",
       " ('sagemiller', 'VB'),\n",
       " (',', ','),\n",
       " ('who', 'WP'),\n",
       " ('holds', 'VBZ'),\n",
       " ('her', 'PRP$'),\n",
       " ('own', 'JJ'),\n",
       " ('throughout', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('entire', 'JJ'),\n",
       " ('film', 'NN'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('actually', 'RB'),\n",
       " ('has', 'VBZ'),\n",
       " ('you', 'PRP'),\n",
       " ('feeling', 'VBG'),\n",
       " ('her', 'PRP$'),\n",
       " ('character', 'NN'),\n",
       " (\"'s\", 'POS'),\n",
       " ('unraveling', 'NN'),\n",
       " ('.', '.'),\n",
       " ('overall', 'JJ'),\n",
       " (',', ','),\n",
       " ('the', 'DT'),\n",
       " ('film', 'NN'),\n",
       " ('does', 'VBZ'),\n",
       " (\"n't\", 'RB'),\n",
       " ('stick', 'VB'),\n",
       " ('because', 'IN'),\n",
       " ('it', 'PRP'),\n",
       " ('does', 'VBZ'),\n",
       " (\"n't\", 'RB'),\n",
       " ('entertain', 'VB'),\n",
       " (',', ','),\n",
       " ('it', 'PRP'),\n",
       " (\"'s\", 'VBZ'),\n",
       " ('confusing', 'VBG'),\n",
       " (',', ','),\n",
       " ('it', 'PRP'),\n",
       " ('rarely', 'RB'),\n",
       " ('excites', 'VBZ'),\n",
       " ('and', 'CC'),\n",
       " ('it', 'PRP'),\n",
       " ('feels', 'VBZ'),\n",
       " ('pretty', 'JJ'),\n",
       " ('redundant', 'NN'),\n",
       " ('for', 'IN'),\n",
       " ('most', 'JJS'),\n",
       " ('of', 'IN'),\n",
       " ('its', 'PRP$'),\n",
       " ('runtime', 'NN'),\n",
       " (',', ','),\n",
       " ('despite', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('pretty', 'JJ'),\n",
       " ('cool', 'NN'),\n",
       " ('ending', 'VBG'),\n",
       " ('and', 'CC'),\n",
       " ('explanation', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('all', 'DT'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('craziness', 'NN'),\n",
       " ('that', 'WDT'),\n",
       " ('came', 'VBD'),\n",
       " ('before', 'IN'),\n",
       " ('it', 'PRP'),\n",
       " ('.', '.'),\n",
       " ('oh', 'UH'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('by', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('way', 'NN'),\n",
       " (',', ','),\n",
       " ('this', 'DT'),\n",
       " ('is', 'VBZ'),\n",
       " ('not', 'RB'),\n",
       " ('a', 'DT'),\n",
       " ('horror', 'NN'),\n",
       " ('or', 'CC'),\n",
       " ('teen', 'JJ'),\n",
       " ('slasher', 'JJR'),\n",
       " ('flick', 'NN'),\n",
       " ('.', '.'),\n",
       " ('.', '.'),\n",
       " ('.', '.'),\n",
       " ('it', 'PRP'),\n",
       " (\"'s\", 'VBZ'),\n",
       " ('just', 'RB'),\n",
       " ('packaged', 'VBN'),\n",
       " ('to', 'TO'),\n",
       " ('look', 'VB'),\n",
       " ('that', 'DT'),\n",
       " ('way', 'NN'),\n",
       " ('because', 'IN'),\n",
       " ('someone', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('apparently', 'RB'),\n",
       " ('assuming', 'VBG'),\n",
       " ('that', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('genre', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('still', 'RB'),\n",
       " ('hot', 'JJ'),\n",
       " ('with', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('kids', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('it', 'PRP'),\n",
       " ('also', 'RB'),\n",
       " ('wrapped', 'VBD'),\n",
       " ('production', 'NN'),\n",
       " ('two', 'CD'),\n",
       " ('years', 'NNS'),\n",
       " ('ago', 'RB'),\n",
       " ('and', 'CC'),\n",
       " ('has', 'VBZ'),\n",
       " ('been', 'VBN'),\n",
       " ('sitting', 'VBG'),\n",
       " ('on', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('shelves', 'NNS'),\n",
       " ('ever', 'RB'),\n",
       " ('since', 'IN'),\n",
       " ('.', '.'),\n",
       " ('whatever', 'NN'),\n",
       " ('.', '.'),\n",
       " ('.', '.'),\n",
       " ('.', '.'),\n",
       " ('skip', 'VB'),\n",
       " ('it', 'PRP'),\n",
       " ('!', '.'),\n",
       " ('where', 'WRB'),\n",
       " (\"'s\", 'POS'),\n",
       " ('joblo', 'NN'),\n",
       " ('coming', 'VBG'),\n",
       " ('from', 'IN'),\n",
       " ('?', '.'),\n",
       " ('a', 'DT'),\n",
       " ('nightmare', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('elm', 'JJ'),\n",
       " ('street', 'NN'),\n",
       " ('3', 'CD'),\n",
       " ('(', '('),\n",
       " ('7/10', 'CD'),\n",
       " (')', ')'),\n",
       " ('-', ':'),\n",
       " ('blair', 'NN'),\n",
       " ('witch', 'NN'),\n",
       " ('2', 'CD'),\n",
       " ('(', '('),\n",
       " ('7/10', 'CD'),\n",
       " (')', ')'),\n",
       " ('-', ':'),\n",
       " ('the', 'DT'),\n",
       " ('crow', 'NN'),\n",
       " ('(', '('),\n",
       " ('9/10', 'CD'),\n",
       " (')', ')'),\n",
       " ('-', ':'),\n",
       " ('the', 'DT'),\n",
       " ('crow', 'NN'),\n",
       " (':', ':'),\n",
       " ('salvation', 'NN'),\n",
       " ('(', '('),\n",
       " ('4/10', 'CD'),\n",
       " (')', ')'),\n",
       " ('-', ':'),\n",
       " ('lost', 'VBN'),\n",
       " ('highway', 'NN'),\n",
       " ('(', '('),\n",
       " ('10/10', 'CD'),\n",
       " (')', ')'),\n",
       " ('-', ':'),\n",
       " ('memento', 'NN'),\n",
       " ('(', '('),\n",
       " ('10/10', 'CD'),\n",
       " (')', ')'),\n",
       " ('-', ':'),\n",
       " ('the', 'DT'),\n",
       " ('others', 'NNS'),\n",
       " ('(', '('),\n",
       " ('9/10', 'CD'),\n",
       " (')', ')'),\n",
       " ('-', ':'),\n",
       " ('stir', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('echoes', 'NNS'),\n",
       " ('(', '('),\n",
       " ('8/10', 'CD'),\n",
       " (')', ')')]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T =[nltk.pos_tag(word_tokenize(t.lower())) for t in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "Filteredlist = ['JJ', 'JJR', 'JJS', 'NN',\n",
    "                'NNP', 'NNS', 'RB', 'RBR', 'RBS', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tfiltered = [str([f[0].lower() for f in x if f[1] in Filteredlist]) for x in T]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(Tfiltered[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   28.3s remaining:   42.4s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   29.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 41.737s\n",
      "\n",
      "Best score: 0.825\n",
      "Best parameters set:\n",
      "\tclf__alpha: 1e-06\n",
      "\tclf__penalty: 'elasticnet'\n",
      "\ttfidf__norm: 'l2'\n",
      "\ttfidf__use_idf: True\n",
      "\tvect__ngram_range: (1, 2)\n"
     ]
    }
   ],
   "source": [
    "grid_searchopt = GridSearchCV(pipelineOptPrep, parametersOpt1, n_jobs=-1, verbose=1, cv=5)\n",
    "LaunchGSearch(grid_searchopt, Tfiltered, y, parametersOpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   38.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 39.370s\n",
      "\n",
      "Best score: 0.685\n",
      "Best parameters set:\n",
      "\ttfidf__norm: 'l1'\n",
      "\ttfidf__use_idf: False\n",
      "\tvect__ngram_range: (1, 1)\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "\n",
    "grid_searchoptRF = GridSearchCV(pipelineRf, parametersOptRf, n_jobs=-1, verbose=1, cv=5)\n",
    "LaunchGSearch(grid_searchoptRF, Tfiltered, y, parametersOptRf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.2min\n",
      "/home/joseph/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/joseph/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/joseph/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/joseph/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/joseph/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/joseph/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/joseph/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/joseph/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/joseph/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/joseph/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/joseph/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/joseph/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/joseph/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/joseph/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/joseph/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/joseph/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/joseph/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/joseph/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/joseph/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/joseph/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/joseph/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/joseph/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/joseph/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/joseph/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/joseph/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/joseph/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/joseph/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/joseph/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/joseph/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/joseph/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/joseph/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/joseph/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/joseph/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/joseph/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/joseph/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/joseph/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/joseph/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joseph/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/joseph/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/joseph/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/joseph/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/joseph/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/joseph/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/joseph/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/joseph/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/joseph/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/joseph/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/joseph/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/joseph/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/joseph/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/joseph/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/joseph/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/joseph/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/joseph/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/joseph/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/joseph/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/joseph/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/joseph/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/joseph/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/joseph/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/joseph/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/joseph/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/joseph/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/joseph/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/joseph/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/joseph/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/joseph/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/joseph/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/joseph/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/joseph/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/joseph/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/joseph/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/joseph/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/joseph/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/joseph/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joseph/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/joseph/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/joseph/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/joseph/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/joseph/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "[Parallel(n_jobs=-1)]: Done 160 out of 160 | elapsed:  7.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 435.039s\n",
      "\n",
      "Best score: 0.860\n",
      "Best parameters set:\n",
      "\tclf__multi_class: 'ovr'\n",
      "\tclf__solver: 'newton-cg'\n",
      "\ttfidf__norm: 'l2'\n",
      "\ttfidf__use_idf: False\n",
      "\tvect__ngram_range: (1, 2)\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "\n",
    "grid_searchoptLR = GridSearchCV(pipelineLR, parametersOptLR, n_jobs=-1, verbose=1, cv=5)\n",
    "LaunchGSearch(grid_searchoptLR, Tfiltered, y, parametersOptLR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### En conclusion nous pouvons voir qu'une simple regression logistique avec un TfIdf nous donne un résultat trés satisfaisant. Le Pos Tag permet d'améliorer de peu les résultats. Le score TfIdf étant aussi trés utile pour relerver les mots pertinents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
